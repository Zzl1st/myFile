tf.get_default_graph() #获取当前默认的计算图
tf.Graph()             #生成新的计算图
tf.add_to_collection() #将资源加入一个或多个集合中
tf.get_collection()    #获取一个集合里面的所有资源

#Tensorflow中维护的集合变量
tf.GraphKeys.VARIABLES   #所有变量都会被自动地加入到这个集合变量中，用于持久化Tensorflow模型;且我们可以通过设置参数trainable的值来决定变量是否能被优化，如果是，则会被加入GraphKeys.TRAINABLE_VARIABLES集合，这个集合也是TF中默认的优化对象
tf.trainable_variables   #得到所有需要优化的参数

tf.GraphKeys.TRAINABLE_VARIABLEs   #可学习的变量（一般指神经网络中的参数），用于模型训练/生成模型可视化内容
tf.GraphKeys.SUMMARIES   #日志生成相关的张量，用于计算可视化
tf.GraphKeys.QUEUE_RUNNERS  #处理输入的QueueRunner，用于输出处理
tf.GraphKeys.MOVING_AVERAGE_VARIABLES   #所有计算了滑动平均值的变量，用于计算变量的滑动平均值

result.get_shape()   #获取结果张量的维度信息
tf.Tensor.eval()     #计算一个张量的取值
tf.InteractiveSession()   #自动将生成的会话注册为默认会话
tf.matmul(x,y)       #矩阵乘法，是矩阵之间的计算，而×是矩阵元素之间的直接相乘
tf.Variable          #保存和更新神经网络中的参数,且一个变量的值在被使用之前，需要被初始化

#Tensorflow中常见的随机数生成函数
tf.random_normal     #正态分布
tf.truncated_normal  #正态分布，但如果随机出来的值偏离平均值超过2个标准差，将被重新随机
tf.random_uniform    #均匀分布
tf.random_gamma      #Gamma分布

#Tensorflow中常见的常数生成函数
tf.zero
tf.ones
tf.fill
tf.constant

tf.global_variables_initializer   #[新]实现初始化所有变量的过程
feed_dict                         #字典，用于给placeholder指定取值

#几种常用的非线性激活函数
tf.nn.relu
tf.sigmoid
tf.tanh
eg:a = tf.nn.relu(tf.matmul(x, w1) + biases1)

tf.clip_by_value         #将一个张量中的数值限制在一个范围之内
tf.log                   #将张量中的所有元素依次取对数
tf.reduce_mean		 #计算平均数
tf.nn.softmax_cross_entropy_with_logits(y, y_)    #实现使用了softmax回归之后的交叉熵损失函数,其中y表示原始神经网络的输出结果，y_表示标准答案
#当分类问题只有一个正确答案时可以使用
tf.nn.sparse_softmax_cross_entropy_with_logits(y, y_)

tf.greater   #输入两个张量，比较这两个张量中每一个元素的大小，并返回比较结果
tf.where(以前叫tf.select)    #有三个参数，第一个为选择条件依据，当为True时，选择第二个参数的值，反之第三个
tf.train.exponential_dacay（0.1,global_step,100,0.96,staircase = True)    #实现了指数衰减学习率,初始学习率0.1,每训练100轮后学习率乘以0.96

tf.contrib.layers.l2_regularizer #返回一个函数，这个函数可以计算一个给定参数的L2正则化项的值
tf.contrib.layers.l1_regularizer #返回一个函数，这个函数可以计算一个给定参数的L1正则化项的值
tf.train.ExponentialMovingAverage  #实现滑动平均模型

input_data.read_data_sets   #自动将Mnist数据集划分为train,validation,test三个数据集
mnist.train.next_batch      #从所有的训练数据中读取一小部分作为一个训练batch

#inference函数可以把整个前向传播的过程抽象为一个函数，里面的参数包含了神经网络中所有的参数，但是一旦变量增多，存储不便，需要找到新的解决方法。
def inference(input_tensor,avg_class,weights1,biases1,weights2,biases2):

#通过一以下两个函数来完成“通过变量名获取变量的机制”
tf.get_variable #创建或者获取变量，变量名称是一个必填的参数，函数会根据这个名字去创建或者获取变量
举例：v = tf.get_variable("v",shape = [1],initializer = tf.constant_initializer(1.0))
     v =tf.Variable(tf.constant(1.0,shape[1],name="v")
tf.variable_scope  #来生成一个上下文管理器，并明确指定在这个上下文管理器中，tf.get_variable将直接获取已经
                   #生成的变量


#TensorFlow中的变量初始化函数
tf.constant_initializer #将变量初始化为给定常量，主要参数是常量的取值
tf.random_normal_initializer  #将变量初始化为满足正态分布的随机值，主要参数是正态分布的均值和标准差
tf.truncated_normal_initializer  #将变量初始化为满足正态分布的随机值，但如果随机出来的值偏离平均值超过两个
                                 #标准差，那么这个数将被重新随机
tf.random_uniform_initializer #将变量初始化为满足平均分布的随机值，主要参数为最大/最小值
tf.uniform_unit_initializer #将变量初始化为满足平均分布但不影响输出数量级的随机值，主要参数是factor(产生随机
                            #值时乘以的系数）
tf.zeros_initializer        #将变量设置为全0,主要参数是变量的维度
tf.ones_initializer         #将变量设置为全1,主要参数是变量的维度

tf.train.Saver

#为了方便加载时重命名滑动平均变量，tf.train.ExponentialMovingAverage提供了
variables_to_restore函数来生成tf.train.Saver类所需要的变量重命名字典

convert_variables_to_constant  #将计算图中的变量及其取值通过常量的方式保存，这样就能将整个TF计算图统一放在一
                               #个文件中
export_meta_graph              #支持以json格式导出MetaGraphDef Protocol Buffer,eg:
                               #saver = tf.train.Saver()
                               #saver.export_meta_graph("/path/.../model.ckpt.meta.json",as_text = True)
